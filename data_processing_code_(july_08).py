# -*- coding: utf-8 -*-
"""DAta_processing_code (july-08).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16FmBeYRHT8nQB32WL3VGmhvA8ocKtwps

This code was used for Precipitation data
"""

# Step 1: Install the necessary packages
!pip install netCDF4 pandas

# Step 2: Upload your files
from google.colab import files
uploaded = files.upload()

# Step 3: Import the required libraries
import netCDF4 as nc
import pandas as pd
import numpy as np
import os

# Step 4: List files in the current directory
print("Files in current directory:")
print(os.listdir())

# Get the correct filenames from the uploaded files
nc_file = None
csv_file = None

for filename in uploaded.keys():
    if filename.endswith('.nc'):
        nc_file = filename
    elif filename.endswith('.csv'):
        csv_file = filename

print("NetCDF file:", nc_file)
print("CSV file:", csv_file)

if nc_file and csv_file:
    # Open the netCDF file
    dataset = nc.Dataset(nc_file)

    # Print the metadata of the netCDF file
    print("\nNetCDF Metadata:")
    print(dataset)

    # List all variables in the netCDF file
    print("\nNetCDF Variables:")
    print(dataset.variables.keys())

    # Read the latitude, longitude, and precipitation variables
    latitudes = dataset.variables['lat'][:]
    longitudes = dataset.variables['lon'][:]
    pr_data = dataset.variables['pr'][:]

    # Print the shapes of the latitude, longitude, and precipitation data
    print("\nShape of latitudes:", latitudes.shape)
    print("Shape of longitudes:", longitudes.shape)
    print("Shape of precipitation data:", pr_data.shape)

    # Read the CSV file
    stations = pd.read_csv(csv_file)

    # Display the first few rows of the stations DataFrame
    print("\nCSV File Content (first few rows):")
    print(stations.head())

    # Print the column names of the CSV file
    print("\nCSV Columns:")
    print(stations.columns)

    # Function to find the nearest index
    def find_nearest(array, value):
        array = np.asarray(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    # Create a DataFrame to store the precipitation data for each station
    station_pr_data = pd.DataFrame()

    # Extract precipitation data for each station
    if 'Lat' in stations.columns and 'Lon' in stations.columns:
        for i, row in stations.iterrows():
            lat_idx = find_nearest(latitudes, row['Lat'])
            lon_idx = find_nearest(longitudes, row['Lon'])
            station_pr = pr_data[:, lat_idx, lon_idx]

            station_pr_data[row['Grid']] = station_pr

        # Transpose the DataFrame so that each station is a column
        station_pr_data = station_pr_data.transpose()
        station_pr_data.columns = [f"Month_{i+1}" for i in range(station_pr_data.shape[1])]
        station_pr_data.insert(0, 'Station', stations['Grid'])

        print("\nPrecipitation Data for Each Station:")
        print(station_pr_data)
    else:
        print("The required columns 'Lat' and/or 'Lon' are not present in the CSV file.")

    # Close the netCDF dataset
    dataset.close()
else:
    print("One or more files were not uploaded correctly.")

import pandas as pd
import os
from google.colab import files

# Define the output folder and file name
output_folder = '/Users/apple/Desktop'
output_excel = os.path.join(output_folder, 'Pr_SSP_2_4.5_MPI-ESM1-2-LR.xlsx')

# Check if the directory exists; if not, create it
if not os.path.exists(output_folder):
    os.makedirs(output_folder)

# Assuming station_pr_data is your DataFrame containing data to save
station_pr_data.to_excel(output_excel, index=False)

print(f"\nPrecipitation data saved to '{output_excel}' file.")
print(station_pr_data)

# Download the file to your local machine
files.download(output_excel)

"""# Now this code we are using for Tasmax values"""

# Step 1: Install the necessary packages
!pip install netCDF4 pandas

# Step 2: Upload your files
from google.colab import files
uploaded = files.upload()

# Step 3: Import the required libraries
import netCDF4 as nc
import pandas as pd
import numpy as np
import os

# Step 4: List files in the current directory
print("Files in current directory:")
print(os.listdir())

# Get the correct filenames from the uploaded files
nc_file = None
csv_file = None

for filename in uploaded.keys():
    if filename.endswith('.nc'):
        nc_file = filename
    elif filename.endswith('.csv'):
        csv_file = filename

print("NetCDF file:", nc_file)
print("CSV file:", csv_file)

if nc_file and csv_file:
    # Open the netCDF file
    dataset = nc.Dataset(nc_file)

    # Print the metadata of the netCDF file
    print("\nNetCDF Metadata:")
    print(dataset)

    # List all variables in the netCDF file
    print("\nNetCDF Variables:")
    print(dataset.variables.keys())

    # Read the latitude, longitude, and tasmax variables
    latitudes = dataset.variables['lat'][:]
    longitudes = dataset.variables['lon'][:]
    tasmax_data = dataset.variables['tasmax'][:]

    # Print the shapes of the latitude, longitude, and tasmax data
    print("\nShape of latitudes:", latitudes.shape)
    print("Shape of longitudes:", longitudes.shape)
    print("Shape of tasmax data:", tasmax_data.shape)

    # Read the CSV file
    stations = pd.read_csv(csv_file)

    # Display the first few rows of the stations DataFrame
    print("\nCSV File Content (first few rows):")
    print(stations.head())

    # Print the column names of the CSV file
    print("\nCSV Columns:")
    print(stations.columns)

    # Function to find the nearest index
    def find_nearest(array, value):
        array = np.asarray(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    # Create a DataFrame to store the tasmax data for each station
    station_tasmax_data = pd.DataFrame()

    # Extract tasmax data for each station
    if 'Lat' in stations.columns and 'Lon' in stations.columns:
        for i, row in stations.iterrows():
            lat_idx = find_nearest(latitudes, row['Lat'])
            lon_idx = find_nearest(longitudes, row['Lon'])
            station_tasmax = tasmax_data[:, lat_idx, lon_idx]

            station_tasmax_data[row['Grid']] = station_tasmax

        # Transpose the DataFrame so that each station is a column
        station_tasmax_data = station_tasmax_data.transpose()
        station_tasmax_data.columns = [f"Month_{i+1}" for i in range(station_tasmax_data.shape[1])]
        station_tasmax_data.insert(0, 'Station', stations['Grid'])

        print("\nTasmax Data for Each Station:")
        print(station_tasmax_data)
    else:
        print("The required columns 'Lat' and/or 'Lon' are not present in the CSV file.")

    # Close the netCDF dataset
    dataset.close()
else:
    print("One or more files were not uploaded correctly.")

import pandas as pd
import os
from google.colab import files

# Define the output file name
output_excel = 'tasmax_SSP_5-8.5_INM-CM5-0.xlsx'

# Assuming station_tasmax_data is your DataFrame containing data to save
station_tasmax_data.to_excel(output_excel, index=False)

print(f"\nTemperature maximum data saved to '{output_excel}' file.")
print(station_tasmax_data)

# Download the file to your local machine
files.download(output_excel)

"""**This code is used for tasmin **"""

# Step 1: Install the necessary packages
!pip install netCDF4 pandas

# Step 2: Upload your files
from google.colab import files
uploaded = files.upload()

# Step 3: Import the required libraries
import netCDF4 as nc
import pandas as pd
import numpy as np
import os

# Step 4: List files in the current directory
print("Files in current directory:")
print(os.listdir())

# Get the correct filenames from the uploaded files
nc_file = None
csv_file = None

for filename in uploaded.keys():
    if filename.endswith('.nc'):
        nc_file = filename
    elif filename.endswith('.csv'):
        csv_file = filename

print("NetCDF file:", nc_file)
print("CSV file:", csv_file)

if nc_file and csv_file:
    # Open the netCDF file
    dataset = nc.Dataset(nc_file)

    # Print the metadata of the netCDF file
    print("\nNetCDF Metadata:")
    print(dataset)

    # List all variables in the netCDF file
    print("\nNetCDF Variables:")
    print(dataset.variables.keys())

    # Read the latitude, longitude, and tasmin variables
    latitudes = dataset.variables['lat'][:]
    longitudes = dataset.variables['lon'][:]
    tasmin_data = dataset.variables['tasmin'][:]

    # Print the shapes of the latitude, longitude, and tasmin data
    print("\nShape of latitudes:", latitudes.shape)
    print("Shape of longitudes:", longitudes.shape)
    print("Shape of tasmin data:", tasmin_data.shape)

    # Read the CSV file
    stations = pd.read_csv(csv_file)

    # Display the first few rows of the stations DataFrame
    print("\nCSV File Content (first few rows):")
    print(stations.head())

    # Print the column names of the CSV file
    print("\nCSV Columns:")
    print(stations.columns)

    # Function to find the nearest index
    def find_nearest(array, value):
        array = np.asarray(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    # Create a DataFrame to store the tasmin data for each station
    station_tasmin_data = pd.DataFrame()

    # Extract tasmin data for each station
    if 'Lat' in stations.columns and 'Lon' in stations.columns:
        for i, row in stations.iterrows():
            lat_idx = find_nearest(latitudes, row['Lat'])
            lon_idx = find_nearest(longitudes, row['Lon'])
            station_tasmin = tasmin_data[:, lat_idx, lon_idx]

            station_tasmin_data[row['Grid']] = station_tasmin

        # Transpose the DataFrame so that each station is a column
        station_tasmin_data = station_tasmin_data.transpose()
        station_tasmin_data.columns = [f"Month_{i+1}" for i in range(station_tasmin_data.shape[1])]
        station_tasmin_data.insert(0, 'Station', stations['Grid'])

        print("\nTasmin Data for Each Station:")
        print(station_tasmin_data)
    else:
        print("The required columns 'Lat' and/or 'Lon' are not present in the CSV file.")

    # Close the netCDF dataset
    dataset.close()
else:
    print("One or more files were not uploaded correctly.")

import pandas as pd
import os
from google.colab import files

# Define the output file name
output_excel = 'tasmin_SSP_2-4.5_MIROC6.xlsx'

# Assuming station_tasmin_data is your DataFrame containing data to save
station_tasmin_data.to_excel(output_excel, index=False)

print(f"\nTemperature minimum data saved to '{output_excel}' file.")
print(station_tasmin_data)

# Download the file to your local machine
files.download(output_excel)