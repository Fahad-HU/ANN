{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This code was used for Precipitation data"
      ],
      "metadata": {
        "id": "Qyf7DxugTleH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "ME5Wgow_WFST",
        "outputId": "a66ad969-a335-4539-f7c4-5fc5b26e8a49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.10/dist-packages (1.7.1.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.10/dist-packages (from netCDF4) (1.6.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from netCDF4) (2024.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from netCDF4) (1.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "^C\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-de8d9101-2cf9-438e-8a7f-8cc7b67ae134\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-de8d9101-2cf9-438e-8a7f-8cc7b67ae134\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-818ea0eb344c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Step 2: Upload your files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Step 3: Import the required libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    157\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    158\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Step 1: Install the necessary packages\n",
        "!pip install netCDF4 pandas\n",
        "\n",
        "# Step 2: Upload your files\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Step 3: Import the required libraries\n",
        "import netCDF4 as nc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Step 4: List files in the current directory\n",
        "print(\"Files in current directory:\")\n",
        "print(os.listdir())\n",
        "\n",
        "# Get the correct filenames from the uploaded files\n",
        "nc_file = None\n",
        "csv_file = None\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.nc'):\n",
        "        nc_file = filename\n",
        "    elif filename.endswith('.csv'):\n",
        "        csv_file = filename\n",
        "\n",
        "print(\"NetCDF file:\", nc_file)\n",
        "print(\"CSV file:\", csv_file)\n",
        "\n",
        "if nc_file and csv_file:\n",
        "    # Open the netCDF file\n",
        "    dataset = nc.Dataset(nc_file)\n",
        "\n",
        "    # Print the metadata of the netCDF file\n",
        "    print(\"\\nNetCDF Metadata:\")\n",
        "    print(dataset)\n",
        "\n",
        "    # List all variables in the netCDF file\n",
        "    print(\"\\nNetCDF Variables:\")\n",
        "    print(dataset.variables.keys())\n",
        "\n",
        "    # Read the latitude, longitude, and precipitation variables\n",
        "    latitudes = dataset.variables['lat'][:]\n",
        "    longitudes = dataset.variables['lon'][:]\n",
        "    pr_data = dataset.variables['pr'][:]\n",
        "\n",
        "    # Print the shapes of the latitude, longitude, and precipitation data\n",
        "    print(\"\\nShape of latitudes:\", latitudes.shape)\n",
        "    print(\"Shape of longitudes:\", longitudes.shape)\n",
        "    print(\"Shape of precipitation data:\", pr_data.shape)\n",
        "\n",
        "    # Read the CSV file\n",
        "    stations = pd.read_csv(csv_file)\n",
        "\n",
        "    # Display the first few rows of the stations DataFrame\n",
        "    print(\"\\nCSV File Content (first few rows):\")\n",
        "    print(stations.head())\n",
        "\n",
        "    # Print the column names of the CSV file\n",
        "    print(\"\\nCSV Columns:\")\n",
        "    print(stations.columns)\n",
        "\n",
        "    # Function to find the nearest index\n",
        "    def find_nearest(array, value):\n",
        "        array = np.asarray(array)\n",
        "        idx = (np.abs(array - value)).argmin()\n",
        "        return idx\n",
        "\n",
        "    # Create a DataFrame to store the precipitation data for each station\n",
        "    station_pr_data = pd.DataFrame()\n",
        "\n",
        "    # Extract precipitation data for each station\n",
        "    if 'Lat' in stations.columns and 'Lon' in stations.columns:\n",
        "        for i, row in stations.iterrows():\n",
        "            lat_idx = find_nearest(latitudes, row['Lat'])\n",
        "            lon_idx = find_nearest(longitudes, row['Lon'])\n",
        "            station_pr = pr_data[:, lat_idx, lon_idx]\n",
        "\n",
        "            station_pr_data[row['Grid']] = station_pr\n",
        "\n",
        "        # Transpose the DataFrame so that each station is a column\n",
        "        station_pr_data = station_pr_data.transpose()\n",
        "        station_pr_data.columns = [f\"Month_{i+1}\" for i in range(station_pr_data.shape[1])]\n",
        "        station_pr_data.insert(0, 'Station', stations['Grid'])\n",
        "\n",
        "        print(\"\\nPrecipitation Data for Each Station:\")\n",
        "        print(station_pr_data)\n",
        "    else:\n",
        "        print(\"The required columns 'Lat' and/or 'Lon' are not present in the CSV file.\")\n",
        "\n",
        "    # Close the netCDF dataset\n",
        "    dataset.close()\n",
        "else:\n",
        "    print(\"One or more files were not uploaded correctly.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GZJCZB85Tjzp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zpqu3FIaWNOL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d36d7dfa-f650-4cf5-e92a-5e86ddd303e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Precipitation data saved to '/Users/apple/Desktop/Pr_SSP_2_4.5_MPI-ESM1-2-LR.xlsx' file.\n",
            "    Station       Month_1       Month_2   Month_3       Month_4       Month_5  \\\n",
            "1       2.0  3.362995e-07  4.480572e-07  0.000009  1.444278e-07  4.602843e-07   \n",
            "2       3.0  1.999586e-07  1.827740e-08  0.000011  3.349137e-08  6.612403e-07   \n",
            "3       4.0  2.035247e-14  7.834470e-07  0.000008  5.398263e-07  8.884281e-07   \n",
            "4       5.0  6.182832e-06  2.949503e-05  0.000029  2.350915e-05  4.143891e-06   \n",
            "5       6.0  5.596723e-06  2.361599e-06  0.000005  4.595034e-06  7.973162e-07   \n",
            "6       7.0  1.390950e-05  2.514007e-06  0.000018  5.700598e-06  1.021152e-05   \n",
            "7       8.0  3.385185e-05  5.679139e-05  0.000052  3.970067e-05  1.311216e-05   \n",
            "8       9.0  3.317653e-05  1.485603e-05  0.000055  2.416716e-05  7.318816e-06   \n",
            "9      10.0  5.596723e-06  2.361599e-06  0.000005  4.595034e-06  7.973162e-07   \n",
            "10     11.0  1.845708e-05  3.600220e-05  0.000039  1.627235e-05  1.011453e-05   \n",
            "11     12.0  5.662863e-06  1.358846e-06  0.000008  3.909131e-06  1.046419e-05   \n",
            "12      NaN  1.939421e-05  6.253938e-06  0.000043  1.777932e-05  8.306902e-06   \n",
            "\n",
            "         Month_6       Month_7       Month_8       Month_9  ...    Month_1023  \\\n",
            "1   1.093283e-08  8.487947e-08  4.268546e-07  1.624310e-10  ...  1.862051e-06   \n",
            "2   3.623524e-08  1.819906e-07  7.976683e-08  1.035447e-08  ...  1.861087e-06   \n",
            "3   5.596095e-09  1.295135e-13  3.018271e-08  7.658369e-18  ...  6.559310e-08   \n",
            "4   2.639001e-06  3.180373e-06  3.224253e-06  2.056659e-08  ...  6.175994e-06   \n",
            "5   5.007500e-07  7.530143e-07  4.359235e-07  9.840067e-18  ...  1.181995e-06   \n",
            "6   6.993749e-07  6.309834e-06  1.509380e-06  4.635458e-06  ...  4.907841e-06   \n",
            "7   3.036037e-06  1.698832e-05  2.935453e-07  4.112618e-06  ...  4.370123e-05   \n",
            "8   1.021455e-06  1.444676e-05  3.021849e-07  6.892277e-06  ...  1.606487e-05   \n",
            "9   5.007500e-07  7.530143e-07  4.359235e-07  9.840067e-18  ...  1.181995e-06   \n",
            "10  3.436450e-06  5.264899e-06  2.817884e-07  5.597011e-06  ...  3.033038e-05   \n",
            "11  5.437640e-07  1.002900e-06  2.493306e-07  8.330750e-07  ...  3.842455e-06   \n",
            "12  1.265950e-06  2.212334e-05  1.080950e-06  7.665007e-06  ...  8.113097e-06   \n",
            "\n",
            "      Month_1024    Month_1025    Month_1026    Month_1027    Month_1028  \\\n",
            "1   6.827190e-23  1.558957e-07  4.824551e-08  8.940489e-08  3.026809e-06   \n",
            "2   8.908868e-09  8.417469e-08  4.613535e-09  5.969209e-08  2.230114e-06   \n",
            "3   1.005991e-07  7.947121e-08  9.201830e-15  2.616895e-15  4.687880e-07   \n",
            "4   2.212322e-06  3.780569e-06  2.145181e-07  6.689135e-07  4.658629e-06   \n",
            "5   2.615788e-07  1.062301e-06  1.430623e-09  6.594090e-11  4.275947e-06   \n",
            "6   1.402654e-06  1.218747e-05  6.228717e-08  1.759677e-07  1.588837e-05   \n",
            "7   1.804758e-05  3.400650e-05  3.701622e-06  2.792088e-06  2.462431e-05   \n",
            "8   4.971726e-06  1.398110e-05  4.002608e-08  5.767813e-07  3.692714e-05   \n",
            "9   2.615788e-07  1.062301e-06  1.430623e-09  6.594090e-11  4.275947e-06   \n",
            "10  1.038106e-05  1.884282e-05  4.754981e-06  2.193230e-06  9.524017e-06   \n",
            "11  1.317362e-06  9.081091e-06  3.829498e-08  4.122131e-08  7.812004e-06   \n",
            "12  2.069038e-06  1.338201e-05  2.454946e-08  8.124157e-08  1.946800e-05   \n",
            "\n",
            "      Month_1029    Month_1030    Month_1031    Month_1032  \n",
            "1   4.392497e-08  1.019599e-07  6.039264e-08  2.010685e-07  \n",
            "2   4.541996e-06  1.008111e-06  3.167841e-07  1.542492e-07  \n",
            "3   2.661766e-07  7.948486e-07  3.876927e-09  7.472697e-08  \n",
            "4   3.612064e-06  4.862024e-06  8.213134e-07  7.137330e-06  \n",
            "5   1.048405e-05  6.347897e-08  1.726236e-07  1.732567e-07  \n",
            "6   1.612661e-05  1.610896e-06  1.585037e-06  5.497495e-07  \n",
            "7   1.775057e-05  3.621922e-07  5.813205e-06  1.350488e-05  \n",
            "8   1.967891e-05  1.341318e-07  3.261343e-06  4.436213e-06  \n",
            "9   1.048405e-05  6.347897e-08  1.726236e-07  1.732567e-07  \n",
            "10  1.251683e-05  3.357756e-07  4.683953e-06  6.415196e-06  \n",
            "11  1.811955e-05  9.615359e-09  8.238561e-07  6.534239e-07  \n",
            "12  1.495310e-05  2.733998e-07  2.803455e-06  1.865444e-06  \n",
            "\n",
            "[12 rows x 1033 columns]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b5d2d200-4222-4d34-ac88-7e7ca93fa37f\", \"Pr_SSP_2_4.5_MPI-ESM1-2-LR.xlsx\", 177037)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Define the output folder and file name\n",
        "output_folder = '/Users/apple/Desktop'\n",
        "output_excel = os.path.join(output_folder, 'Pr_SSP_2_4.5_MPI-ESM1-2-LR.xlsx')\n",
        "\n",
        "# Check if the directory exists; if not, create it\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Assuming station_pr_data is your DataFrame containing data to save\n",
        "station_pr_data.to_excel(output_excel, index=False)\n",
        "\n",
        "print(f\"\\nPrecipitation data saved to '{output_excel}' file.\")\n",
        "print(station_pr_data)\n",
        "\n",
        "# Download the file to your local machine\n",
        "files.download(output_excel)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now this code we are using for Tasmax values"
      ],
      "metadata": {
        "id": "zuK9S4fJTXj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install the necessary packages\n",
        "!pip install netCDF4 pandas\n",
        "\n",
        "# Step 2: Upload your files\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Step 3: Import the required libraries\n",
        "import netCDF4 as nc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Step 4: List files in the current directory\n",
        "print(\"Files in current directory:\")\n",
        "print(os.listdir())\n",
        "\n",
        "# Get the correct filenames from the uploaded files\n",
        "nc_file = None\n",
        "csv_file = None\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.nc'):\n",
        "        nc_file = filename\n",
        "    elif filename.endswith('.csv'):\n",
        "        csv_file = filename\n",
        "\n",
        "print(\"NetCDF file:\", nc_file)\n",
        "print(\"CSV file:\", csv_file)\n",
        "\n",
        "if nc_file and csv_file:\n",
        "    # Open the netCDF file\n",
        "    dataset = nc.Dataset(nc_file)\n",
        "\n",
        "    # Print the metadata of the netCDF file\n",
        "    print(\"\\nNetCDF Metadata:\")\n",
        "    print(dataset)\n",
        "\n",
        "    # List all variables in the netCDF file\n",
        "    print(\"\\nNetCDF Variables:\")\n",
        "    print(dataset.variables.keys())\n",
        "\n",
        "    # Read the latitude, longitude, and tasmax variables\n",
        "    latitudes = dataset.variables['lat'][:]\n",
        "    longitudes = dataset.variables['lon'][:]\n",
        "    tasmax_data = dataset.variables['tasmax'][:]\n",
        "\n",
        "    # Print the shapes of the latitude, longitude, and tasmax data\n",
        "    print(\"\\nShape of latitudes:\", latitudes.shape)\n",
        "    print(\"Shape of longitudes:\", longitudes.shape)\n",
        "    print(\"Shape of tasmax data:\", tasmax_data.shape)\n",
        "\n",
        "    # Read the CSV file\n",
        "    stations = pd.read_csv(csv_file)\n",
        "\n",
        "    # Display the first few rows of the stations DataFrame\n",
        "    print(\"\\nCSV File Content (first few rows):\")\n",
        "    print(stations.head())\n",
        "\n",
        "    # Print the column names of the CSV file\n",
        "    print(\"\\nCSV Columns:\")\n",
        "    print(stations.columns)\n",
        "\n",
        "    # Function to find the nearest index\n",
        "    def find_nearest(array, value):\n",
        "        array = np.asarray(array)\n",
        "        idx = (np.abs(array - value)).argmin()\n",
        "        return idx\n",
        "\n",
        "    # Create a DataFrame to store the tasmax data for each station\n",
        "    station_tasmax_data = pd.DataFrame()\n",
        "\n",
        "    # Extract tasmax data for each station\n",
        "    if 'Lat' in stations.columns and 'Lon' in stations.columns:\n",
        "        for i, row in stations.iterrows():\n",
        "            lat_idx = find_nearest(latitudes, row['Lat'])\n",
        "            lon_idx = find_nearest(longitudes, row['Lon'])\n",
        "            station_tasmax = tasmax_data[:, lat_idx, lon_idx]\n",
        "\n",
        "            station_tasmax_data[row['Grid']] = station_tasmax\n",
        "\n",
        "        # Transpose the DataFrame so that each station is a column\n",
        "        station_tasmax_data = station_tasmax_data.transpose()\n",
        "        station_tasmax_data.columns = [f\"Month_{i+1}\" for i in range(station_tasmax_data.shape[1])]\n",
        "        station_tasmax_data.insert(0, 'Station', stations['Grid'])\n",
        "\n",
        "        print(\"\\nTasmax Data for Each Station:\")\n",
        "        print(station_tasmax_data)\n",
        "    else:\n",
        "        print(\"The required columns 'Lat' and/or 'Lon' are not present in the CSV file.\")\n",
        "\n",
        "    # Close the netCDF dataset\n",
        "    dataset.close()\n",
        "else:\n",
        "    print(\"One or more files were not uploaded correctly.\")\n"
      ],
      "metadata": {
        "id": "HuAr2KoVTZr8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0034a04b-2b12-4591-8fd2-85988a70ecc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.10/dist-packages (1.7.1.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.10/dist-packages (from netCDF4) (1.6.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from netCDF4) (2024.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from netCDF4) (1.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7e72fb62-208d-46e8-a1ff-6b9d17777a05\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7e72fb62-208d-46e8-a1ff-6b9d17777a05\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving station_name.csv to station_name (12).csv\n",
            "Saving tasmax_Amon_INM-CM5-0_ssp585_r1i1p1f1_gr1_20150116-21001216_v20190724.nc to tasmax_Amon_INM-CM5-0_ssp585_r1i1p1f1_gr1_20150116-21001216_v20190724.nc\n",
            "Files in current directory:\n",
            "['.config', 'tasmax_Amon_IPSL-CM6A-LR_ssp245_r1i1p1f1_gr_20150116-21001216_v20190119.nc', 'tasmax_SSP_2_4.5_MIROC6.xlsx', 'station_name.csv', 'pr_Amon_MIROC6_ssp585_r1i1p1f1_gn_20150116-21001216_v20190627.nc', 'tasmin_Amon_MIROC6_ssp585_r1i1p1f1_gn_20150116-21001216_v20190627.nc', 'tasmax_SSP_2-4.5_INM-CM5-0.xlsx', 'tasmax_Amon_IPSL-CM6A-LR_ssp585_r1i1p1f1_gr_20150116-21001216_v20190903.nc', 'tasmax_Amon_INM-CM5-0_ssp245_r1i1p1f1_gr1_20150116-21001216_v20190619.nc', 'tasmax_SSP_5_8.5_MIROC6.xlsx', 'station_name (6).csv', 'tasmax_SSP_5_8.5_MRI-ESM2-0.xlsx', 'station_name (7).csv', 'station_name (2).csv', 'station_name (8).csv', 'tasmax_Amon_MRI-ESM2-0_ssp585_r1i1p1f1_gn_20150116-21001216_v20191108.nc', 'pr_Amon_MRI-ESM2-0_ssp245_r1i1p1f1_gn_20150116-21001216_v20190222.nc', 'tasmax_SSP_5-8.5_IPSL-CM6A-LR.xlsx', 'station_name (11).csv', 'pr_Amon_MPI-ESM1-2-LR_ssp245_r1i1p1f1_gn_20150116-21001216_v20190710.nc', 'tasmax_Amon_MPI-ESM1-2-LR_ssp585_r1i1p1f1_gn_20150116-21001216_v20190710.nc', 'tasmax_Amon_INM-CM5-0_ssp585_r1i1p1f1_gr1_20150116-21001216_v20190724.nc', 'station_name (12).csv', 'tasmax_SSP_2_4.5_MRI-ESM2-0.xlsx', 'station_name (10).csv', 'tasmax_SSP_2_4.5_IPSL-CM6A-LR.xlsx', 'station_name (4).csv', 'station_name (9).csv', 'tasmax_Amon_MPI-ESM1-2-LR_ssp245_r1i1p1f1_gn_20150116-21001216_v20190710.nc', 'station_name (5).csv', 'tasmax_Amon_MRI-ESM2-0_ssp245_r1i1p1f1_gn_20150116-21001216_v20190222.nc', 'station_name (1).csv', 'tasmax_Amon_MIROC6_ssp245_r1i1p1f1_gn_20150116-21001216_v20190627.nc', 'station_name (3).csv', 'tasmax_SSP_2_4.5_MPI-ESM1-2-LR.xlsx', 'sample_data']\n",
            "NetCDF file: tasmax_Amon_INM-CM5-0_ssp585_r1i1p1f1_gr1_20150116-21001216_v20190724.nc\n",
            "CSV file: station_name (12).csv\n",
            "\n",
            "NetCDF Metadata:\n",
            "<class 'netCDF4._netCDF4.Dataset'>\n",
            "root group (NETCDF4 data model, file format HDF5):\n",
            "    Conventions: CF-1.7 CMIP-6.2\n",
            "    activity_id: ScenarioMIP\n",
            "    branch_method: standard\n",
            "    branch_time_in_child: 60225.0\n",
            "    branch_time_in_parent: 60225.0\n",
            "    contact: Evgeny Volodin (volodinev@gmail.com)\n",
            "    creation_date: 2019-07-23T20:22:44Z\n",
            "    data_specs_version: 01.00.29\n",
            "    experiment: update of RCP8.5 based on SSP5\n",
            "    experiment_id: ssp585\n",
            "    external_variables: areacella\n",
            "    forcing_index: 1\n",
            "    frequency: mon\n",
            "    further_info_url: https://furtherinfo.es-doc.org/CMIP6.INM.INM-CM5-0.ssp585.none.r1i1p1f1\n",
            "    grid: gs2x1.5\n",
            "    grid_label: gr1\n",
            "    history: 2019-07-23T20:22:44Z ;rewrote data to be consistent with ScenarioMIP for variable ccb found in table Amon.\n",
            "    initialization_index: 1\n",
            "    institution: Institute for Numerical Mathematics, Russian Academy of Science, Moscow 119991, Russia\n",
            "    institution_id: INM\n",
            "    mip_era: CMIP6\n",
            "    nominal_resolution: 100 km\n",
            "    parent_activity_id: CMIP\n",
            "    parent_experiment_id: historical\n",
            "    parent_mip_era: CMIP6\n",
            "    parent_source_id: INM-CM5-0\n",
            "    parent_time_units: days since 1850-01-01\n",
            "    parent_variant_label: r1i1p1f1\n",
            "    physics_index: 1\n",
            "    product: model-output\n",
            "    realization_index: 1\n",
            "    realm: atmos\n",
            "    references: RJNAMM 2018, 367-374. DOI: 10.1515/rnam-2018-0032\n",
            "    run_variant: standard\n",
            "    source: INM-CM5-0 (2016): \n",
            "aerosol: INM-AER1\n",
            "atmos: INM-AM5-0 (2x1.5; 180 x 120 longitude/latitude; 73 levels; top level sigma = 0.0002)\n",
            "atmosChem: none\n",
            "land: INM-LND1\n",
            "landIce: none\n",
            "ocean: INM-OM5 (North Pole shifted to 60N, 90E. 0.5x0.25; 720 x 720 longitude/latitude; 40 levels; vertical sigma coordinate)\n",
            "ocnBgchem: none\n",
            "seaIce: INM-ICE1\n",
            "    source_id: INM-CM5-0\n",
            "    source_type: AOGCM AER\n",
            "    sub_experiment: none\n",
            "    sub_experiment_id: none\n",
            "    table_id: Amon\n",
            "    table_info: Creation Date:(20 February 2019) MD5:951084b632bd52c3f6224e495b1cb65e\n",
            "    title: INM-CM5-0 output prepared for CMIP6\n",
            "    tracking_id: hdl:21.14100/be108741-2932-4b98-b8d0-2b63ecaecb80\n",
            "    variable_id: tasmax\n",
            "    variant_label: r1i1p1f1\n",
            "    license: CMIP6 model data produced by Lawrence Livermore PCMDI is licensed under a Creative Commons Attribution ShareAlike 4.0 International License (https://creativecommons.org/licenses). Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment. Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file) and at https:///pcmdi.llnl.gov/. The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.\n",
            "    cmor_version: 3.4.0\n",
            "    dimensions(sizes): time(1032), bnds(2), lat(120), lon(180)\n",
            "    variables(dimensions): float64 time(time), float64 time_bnds(time, bnds), float64 lat(lat), float64 lat_bnds(lat, bnds), float64 lon(lon), float64 lon_bnds(lon, bnds), float64 height(), float32 tasmax(time, lat, lon)\n",
            "    groups: \n",
            "\n",
            "NetCDF Variables:\n",
            "dict_keys(['time', 'time_bnds', 'lat', 'lat_bnds', 'lon', 'lon_bnds', 'height', 'tasmax'])\n",
            "\n",
            "Shape of latitudes: (120,)\n",
            "Shape of longitudes: (180,)\n",
            "Shape of tasmax data: (1032, 120, 180)\n",
            "\n",
            "CSV File Content (first few rows):\n",
            "     Lat    Lon  Grid\n",
            "0  24.88  66.56     1\n",
            "1  25.39  68.40     2\n",
            "2  27.32  68.14     3\n",
            "3  30.20  66.91     4\n",
            "4  29.20  71.47     5\n",
            "\n",
            "CSV Columns:\n",
            "Index(['Lat', 'Lon', 'Grid'], dtype='object')\n",
            "\n",
            "Tasmax Data for Each Station:\n",
            "    Station     Month_1     Month_2     Month_3     Month_4     Month_5  \\\n",
            "1       2.0  299.338501  304.776825  308.666046  312.929382  311.583862   \n",
            "2       3.0  299.829742  305.330170  310.013672  314.122070  313.062836   \n",
            "3       4.0  295.651428  301.873138  308.086517  311.736694  315.065155   \n",
            "4       5.0  285.715118  292.258606  297.483887  299.796844  305.595520   \n",
            "5       6.0  292.670197  299.809296  306.585632  310.970978  311.077911   \n",
            "6       7.0  291.981537  298.914581  304.883881  309.636078  310.655487   \n",
            "7       8.0  278.517914  284.717804  293.248047  295.948395  301.172791   \n",
            "8       9.0  288.298309  295.500427  301.164581  305.691071  307.340027   \n",
            "9      10.0  291.266235  298.589813  305.074158  309.156464  310.341797   \n",
            "10     11.0  278.517914  284.717804  293.248047  295.948395  301.172791   \n",
            "11     12.0  288.435181  296.380615  302.976776  306.224213  308.634766   \n",
            "12      NaN  288.298309  295.500427  301.164581  305.691071  307.340027   \n",
            "\n",
            "       Month_6     Month_7     Month_8     Month_9  ...  Month_1023  \\\n",
            "1   306.424530  303.668335  303.116516  307.223602  ...  313.699707   \n",
            "2   307.228302  305.654724  301.900665  307.759338  ...  314.290222   \n",
            "3   314.723785  314.409210  314.650177  314.469513  ...  310.239868   \n",
            "4   310.002838  312.553802  311.229584  305.698364  ...  298.534149   \n",
            "5   315.523132  315.900970  313.212189  313.703186  ...  307.626892   \n",
            "6   315.550964  315.940826  309.772705  312.406311  ...  306.020660   \n",
            "7   308.474701  311.812683  310.042969  306.003052  ...  294.711517   \n",
            "8   313.877838  314.783997  306.258911  309.894165  ...  302.955383   \n",
            "9   316.230835  317.644897  314.248352  313.613373  ...  306.044983   \n",
            "10  308.474701  311.812683  310.042969  306.003052  ...  294.711517   \n",
            "11  315.658691  317.826813  314.248993  312.673126  ...  304.034149   \n",
            "12  313.877838  314.783997  306.258911  309.894165  ...  302.955383   \n",
            "\n",
            "    Month_1024  Month_1025  Month_1026  Month_1027  Month_1028  Month_1029  \\\n",
            "1   316.238159  311.975159  307.213043  306.860504  305.010986  311.212311   \n",
            "2   317.794128  314.205780  309.434845  309.590607  304.378143  312.751099   \n",
            "3   317.870514  317.834900  318.125031  317.183990  315.692230  318.453583   \n",
            "4   307.776062  310.165222  314.635529  317.840851  315.623962  312.410522   \n",
            "5   317.074280  318.420135  319.963806  319.591431  313.487122  316.296326   \n",
            "6   316.007446  316.845184  319.462250  316.881622  309.189789  311.321442   \n",
            "7   305.860229  309.302246  312.502594  316.385651  311.177032  309.870483   \n",
            "8   313.190277  313.723175  316.394562  315.653107  305.337341  307.026917   \n",
            "9   315.903412  317.895233  320.472351  320.667908  313.681824  315.081421   \n",
            "10  305.860229  309.302246  312.502594  316.385651  311.177032  309.870483   \n",
            "11  314.241974  316.349457  319.184662  320.735474  312.237946  313.926544   \n",
            "12  313.190277  313.723175  316.394562  315.653107  305.337341  307.026917   \n",
            "\n",
            "    Month_1030  Month_1031  Month_1032  \n",
            "1   313.198364  309.746155  304.536530  \n",
            "2   314.094910  310.694794  305.573639  \n",
            "3   313.764679  307.485016  300.951599  \n",
            "4   304.621155  299.283508  292.690277  \n",
            "5   311.207886  305.449158  299.741333  \n",
            "6   307.873474  304.095123  299.404877  \n",
            "7   300.738983  296.751129  291.782959  \n",
            "8   303.011963  300.752777  296.949860  \n",
            "9   308.374420  304.049164  298.899078  \n",
            "10  300.738983  296.751129  291.782959  \n",
            "11  305.429169  302.793549  297.766937  \n",
            "12  303.011963  300.752777  296.949860  \n",
            "\n",
            "[12 rows x 1033 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Define the output file name\n",
        "output_excel = 'tasmax_SSP_5-8.5_INM-CM5-0.xlsx'\n",
        "\n",
        "# Assuming station_tasmax_data is your DataFrame containing data to save\n",
        "station_tasmax_data.to_excel(output_excel, index=False)\n",
        "\n",
        "print(f\"\\nTemperature maximum data saved to '{output_excel}' file.\")\n",
        "print(station_tasmax_data)\n",
        "\n",
        "# Download the file to your local machine\n",
        "files.download(output_excel)"
      ],
      "metadata": {
        "id": "WT6ZCPPzTxCW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d8890c62-4c82-4421-a246-3bbed350e093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Temperature maximum data saved to 'tasmax_SSP_5-8.5_INM-CM5-0.xlsx' file.\n",
            "    Station     Month_1     Month_2     Month_3     Month_4     Month_5  \\\n",
            "1       2.0  299.338501  304.776825  308.666046  312.929382  311.583862   \n",
            "2       3.0  299.829742  305.330170  310.013672  314.122070  313.062836   \n",
            "3       4.0  295.651428  301.873138  308.086517  311.736694  315.065155   \n",
            "4       5.0  285.715118  292.258606  297.483887  299.796844  305.595520   \n",
            "5       6.0  292.670197  299.809296  306.585632  310.970978  311.077911   \n",
            "6       7.0  291.981537  298.914581  304.883881  309.636078  310.655487   \n",
            "7       8.0  278.517914  284.717804  293.248047  295.948395  301.172791   \n",
            "8       9.0  288.298309  295.500427  301.164581  305.691071  307.340027   \n",
            "9      10.0  291.266235  298.589813  305.074158  309.156464  310.341797   \n",
            "10     11.0  278.517914  284.717804  293.248047  295.948395  301.172791   \n",
            "11     12.0  288.435181  296.380615  302.976776  306.224213  308.634766   \n",
            "12      NaN  288.298309  295.500427  301.164581  305.691071  307.340027   \n",
            "\n",
            "       Month_6     Month_7     Month_8     Month_9  ...  Month_1023  \\\n",
            "1   306.424530  303.668335  303.116516  307.223602  ...  313.699707   \n",
            "2   307.228302  305.654724  301.900665  307.759338  ...  314.290222   \n",
            "3   314.723785  314.409210  314.650177  314.469513  ...  310.239868   \n",
            "4   310.002838  312.553802  311.229584  305.698364  ...  298.534149   \n",
            "5   315.523132  315.900970  313.212189  313.703186  ...  307.626892   \n",
            "6   315.550964  315.940826  309.772705  312.406311  ...  306.020660   \n",
            "7   308.474701  311.812683  310.042969  306.003052  ...  294.711517   \n",
            "8   313.877838  314.783997  306.258911  309.894165  ...  302.955383   \n",
            "9   316.230835  317.644897  314.248352  313.613373  ...  306.044983   \n",
            "10  308.474701  311.812683  310.042969  306.003052  ...  294.711517   \n",
            "11  315.658691  317.826813  314.248993  312.673126  ...  304.034149   \n",
            "12  313.877838  314.783997  306.258911  309.894165  ...  302.955383   \n",
            "\n",
            "    Month_1024  Month_1025  Month_1026  Month_1027  Month_1028  Month_1029  \\\n",
            "1   316.238159  311.975159  307.213043  306.860504  305.010986  311.212311   \n",
            "2   317.794128  314.205780  309.434845  309.590607  304.378143  312.751099   \n",
            "3   317.870514  317.834900  318.125031  317.183990  315.692230  318.453583   \n",
            "4   307.776062  310.165222  314.635529  317.840851  315.623962  312.410522   \n",
            "5   317.074280  318.420135  319.963806  319.591431  313.487122  316.296326   \n",
            "6   316.007446  316.845184  319.462250  316.881622  309.189789  311.321442   \n",
            "7   305.860229  309.302246  312.502594  316.385651  311.177032  309.870483   \n",
            "8   313.190277  313.723175  316.394562  315.653107  305.337341  307.026917   \n",
            "9   315.903412  317.895233  320.472351  320.667908  313.681824  315.081421   \n",
            "10  305.860229  309.302246  312.502594  316.385651  311.177032  309.870483   \n",
            "11  314.241974  316.349457  319.184662  320.735474  312.237946  313.926544   \n",
            "12  313.190277  313.723175  316.394562  315.653107  305.337341  307.026917   \n",
            "\n",
            "    Month_1030  Month_1031  Month_1032  \n",
            "1   313.198364  309.746155  304.536530  \n",
            "2   314.094910  310.694794  305.573639  \n",
            "3   313.764679  307.485016  300.951599  \n",
            "4   304.621155  299.283508  292.690277  \n",
            "5   311.207886  305.449158  299.741333  \n",
            "6   307.873474  304.095123  299.404877  \n",
            "7   300.738983  296.751129  291.782959  \n",
            "8   303.011963  300.752777  296.949860  \n",
            "9   308.374420  304.049164  298.899078  \n",
            "10  300.738983  296.751129  291.782959  \n",
            "11  305.429169  302.793549  297.766937  \n",
            "12  303.011963  300.752777  296.949860  \n",
            "\n",
            "[12 rows x 1033 columns]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_37e43ba7-3c38-4ceb-a8ce-0a62d0b0f15e\", \"tasmax_SSP_5-8.5_INM-CM5-0.xlsx\", 130797)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This code is used for tasmin **"
      ],
      "metadata": {
        "id": "qQ2CXyIPTyl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install the necessary packages\n",
        "!pip install netCDF4 pandas\n",
        "\n",
        "# Step 2: Upload your files\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Step 3: Import the required libraries\n",
        "import netCDF4 as nc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Step 4: List files in the current directory\n",
        "print(\"Files in current directory:\")\n",
        "print(os.listdir())\n",
        "\n",
        "# Get the correct filenames from the uploaded files\n",
        "nc_file = None\n",
        "csv_file = None\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.nc'):\n",
        "        nc_file = filename\n",
        "    elif filename.endswith('.csv'):\n",
        "        csv_file = filename\n",
        "\n",
        "print(\"NetCDF file:\", nc_file)\n",
        "print(\"CSV file:\", csv_file)\n",
        "\n",
        "if nc_file and csv_file:\n",
        "    # Open the netCDF file\n",
        "    dataset = nc.Dataset(nc_file)\n",
        "\n",
        "    # Print the metadata of the netCDF file\n",
        "    print(\"\\nNetCDF Metadata:\")\n",
        "    print(dataset)\n",
        "\n",
        "    # List all variables in the netCDF file\n",
        "    print(\"\\nNetCDF Variables:\")\n",
        "    print(dataset.variables.keys())\n",
        "\n",
        "    # Read the latitude, longitude, and tasmin variables\n",
        "    latitudes = dataset.variables['lat'][:]\n",
        "    longitudes = dataset.variables['lon'][:]\n",
        "    tasmin_data = dataset.variables['tasmin'][:]\n",
        "\n",
        "    # Print the shapes of the latitude, longitude, and tasmin data\n",
        "    print(\"\\nShape of latitudes:\", latitudes.shape)\n",
        "    print(\"Shape of longitudes:\", longitudes.shape)\n",
        "    print(\"Shape of tasmin data:\", tasmin_data.shape)\n",
        "\n",
        "    # Read the CSV file\n",
        "    stations = pd.read_csv(csv_file)\n",
        "\n",
        "    # Display the first few rows of the stations DataFrame\n",
        "    print(\"\\nCSV File Content (first few rows):\")\n",
        "    print(stations.head())\n",
        "\n",
        "    # Print the column names of the CSV file\n",
        "    print(\"\\nCSV Columns:\")\n",
        "    print(stations.columns)\n",
        "\n",
        "    # Function to find the nearest index\n",
        "    def find_nearest(array, value):\n",
        "        array = np.asarray(array)\n",
        "        idx = (np.abs(array - value)).argmin()\n",
        "        return idx\n",
        "\n",
        "    # Create a DataFrame to store the tasmin data for each station\n",
        "    station_tasmin_data = pd.DataFrame()\n",
        "\n",
        "    # Extract tasmin data for each station\n",
        "    if 'Lat' in stations.columns and 'Lon' in stations.columns:\n",
        "        for i, row in stations.iterrows():\n",
        "            lat_idx = find_nearest(latitudes, row['Lat'])\n",
        "            lon_idx = find_nearest(longitudes, row['Lon'])\n",
        "            station_tasmin = tasmin_data[:, lat_idx, lon_idx]\n",
        "\n",
        "            station_tasmin_data[row['Grid']] = station_tasmin\n",
        "\n",
        "        # Transpose the DataFrame so that each station is a column\n",
        "        station_tasmin_data = station_tasmin_data.transpose()\n",
        "        station_tasmin_data.columns = [f\"Month_{i+1}\" for i in range(station_tasmin_data.shape[1])]\n",
        "        station_tasmin_data.insert(0, 'Station', stations['Grid'])\n",
        "\n",
        "        print(\"\\nTasmin Data for Each Station:\")\n",
        "        print(station_tasmin_data)\n",
        "    else:\n",
        "        print(\"The required columns 'Lat' and/or 'Lon' are not present in the CSV file.\")\n",
        "\n",
        "    # Close the netCDF dataset\n",
        "    dataset.close()\n",
        "else:\n",
        "    print(\"One or more files were not uploaded correctly.\")\n"
      ],
      "metadata": {
        "id": "yKO5R4JTT6MR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Define the output file name\n",
        "output_excel = 'tasmax_SSP_2-4.5_MIROC6.xlsx'\n",
        "\n",
        "# Assuming station_tasmax_data is your DataFrame containing data to save\n",
        "station_tasmin_data.to_excel(output_excel, index=False)\n",
        "\n",
        "print(f\"\\nTemperature maximum data saved to '{output_excel}' file.\")\n",
        "print(station_tasmin_data)\n",
        "\n",
        "# Download the file to your local machine\n",
        "files.download(output_excel)"
      ],
      "metadata": {
        "id": "AQ_xRw7ApRFB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}